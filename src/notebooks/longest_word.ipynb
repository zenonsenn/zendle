{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8295e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "import re\n",
    "from pprint import pprint\n",
    "\n",
    "WORDLIST_LOCATION = os.getenv(\"WORDLIST_LOCATION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "25bb080c",
   "metadata": {},
   "outputs": [],
   "source": [
    "letters_only = \"[a-z]\"\n",
    "\n",
    "wordlist = None\n",
    "with open(WORDLIST_LOCATION) as f:\n",
    "    wordlist = f.read()\n",
    "\n",
    "wordlist = wordlist.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "45b1ab55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': [28, 239503, 25417], 'b': [23, 155339, 18413], 'c': [29, 303414, 32108], 'd': [31, 174945, 18733], 'e': [27, 135433, 14197], 'f': [24, 101370, 11893], 'g': [23, 92884, 10953], 'h': [28, 132135, 13743], 'i': [25, 138272, 13199], 'y': [15, 7611, 1143], 'j': [18, 21555, 2840], 'k': [20, 29418, 3952], 'l': [22, 85033, 10002], 'm': [27, 185652, 19805], 'n': [22, 149792, 13459], 'o': [23, 125685, 12681], 'p': [25, 354009, 34860], 'q': [19, 16578, 1793], 'r': [25, 153034, 16783], 's': [25, 363463, 38764], 't': [29, 170673, 18819], 'u': [22, 243503, 22766], 'v': [20, 47077, 5329], 'w': [19, 52341, 6559], 'x': [16, 4593, 507], 'z': [22, 11388, 1387], '': [0, 0, 1]}\n"
     ]
    }
   ],
   "source": [
    "lengths = {}\n",
    "# {letter: [max_length, letter_count, word_count]}\n",
    "for word in wordlist:\n",
    "    current_letter = word[:1]\n",
    "    try:\n",
    "        current_max = lengths[current_letter][0]\n",
    "        lengths.update({word[:1]: [\n",
    "            lengths[current_letter][0], \n",
    "            (lengths[current_letter][1] + len(word)),\n",
    "            lengths[current_letter][2] + 1\n",
    "        ]})\n",
    "        if len(word) > current_max:\n",
    "            lengths.update({word[:1]: [\n",
    "                len(word), \n",
    "                lengths[current_letter][1],\n",
    "                lengths[current_letter][2]\n",
    "            ]})\n",
    "    except:\n",
    "        lengths.update({word[:1]: [\n",
    "            len(word), \n",
    "            len(word), \n",
    "            1\n",
    "        ]})\n",
    "\n",
    "print(lengths)\n",
    "\n",
    "lengths = dict(sorted(lengths.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0239572",
   "metadata": {},
   "source": [
    "Letter count per letter per word distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "69b7e8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a 0.0685\n",
      "b 0.0444\n",
      "c 0.0868\n",
      "d 0.0501\n",
      "e 0.0388\n",
      "f 0.029\n",
      "g 0.0266\n",
      "h 0.0378\n",
      "i 0.0396\n",
      "j 0.0062\n",
      "k 0.0084\n",
      "l 0.0243\n",
      "m 0.0531\n",
      "n 0.0429\n",
      "o 0.036\n",
      "p 0.1013\n",
      "q 0.0047\n",
      "r 0.0438\n",
      "s 0.104\n",
      "t 0.0488\n",
      "u 0.0697\n",
      "v 0.0135\n",
      "w 0.015\n",
      "x 0.0013\n",
      "y 0.0022\n",
      "z 0.0033\n"
     ]
    }
   ],
   "source": [
    "letter_count_sum = 0\n",
    "for item in lengths:\n",
    "    letter_count_sum += lengths[item][1]\n",
    "\n",
    "for item in lengths:\n",
    "    if item != \"\":\n",
    "        print(item, np.round(lengths[item][1] / letter_count_sum,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad2fa83",
   "metadata": {},
   "source": [
    "Word count per letter  distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b8b8d3f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a 3.8641\n",
      "b 4.3291\n",
      "c 3.5269\n",
      "d 4.3043\n",
      "e 4.7043\n",
      "f 4.9598\n",
      "g 5.0785\n",
      "h 4.7512\n",
      "i 4.8094\n",
      "j 7.0259\n",
      "k 6.5492\n",
      "l 5.2096\n",
      "m 4.224\n",
      "n 4.7813\n",
      "o 4.8672\n",
      "p 3.4083\n",
      "q 7.6894\n",
      "r 4.4629\n",
      "s 3.2551\n",
      "t 4.2977\n",
      "u 4.023\n",
      "v 6.1179\n",
      "w 5.8183\n",
      "x 9.5117\n",
      "y 8.339\n",
      "z 8.0598\n"
     ]
    }
   ],
   "source": [
    "word_count_sum = 0\n",
    "for item in lengths:\n",
    "    word_count_sum += lengths[item][2]\n",
    "\n",
    "for item in lengths:\n",
    "    if item != \"\":\n",
    "        print(item, np.round(abs(np.log2(lengths[item][2] / word_count_sum)),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3e309057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a 1.4564\n",
      "b 1.6316\n",
      "c 1.3293\n",
      "d 1.6223\n",
      "e 1.773\n",
      "f 1.8693\n",
      "g 1.9141\n",
      "h 1.7907\n",
      "i 1.8127\n",
      "j 7.0259\n",
      "k 6.5492\n",
      "l 1.9635\n",
      "m 1.592\n",
      "n 1.8021\n",
      "o 1.8344\n",
      "p 1.2846\n",
      "q 7.6894\n",
      "r 1.682\n",
      "s 1.2269\n",
      "t 1.6198\n",
      "u 1.5163\n",
      "v 6.1179\n",
      "w 5.8183\n",
      "x 9.5117\n",
      "y 8.339\n",
      "z 8.0598\n"
     ]
    }
   ],
   "source": [
    "word_rebalanced_sum = 0\n",
    "for item in lengths:\n",
    "    if item != \"\":\n",
    "        word_rebalanced_sum += abs(np.log2(lengths[item][2] / word_count_sum))\n",
    "\n",
    "word_rebalanced_avg = word_rebalanced_sum / 26\n",
    "\n",
    "for item in lengths:\n",
    "    if item != \"\" and abs(np.log2(lengths[item][2] / word_count_sum)) > word_rebalanced_avg:\n",
    "        print(item, np.round(abs(np.log2(lengths[item][2] / word_count_sum)), 4))\n",
    "    if item != \"\" and abs(np.log2(lengths[item][2] / word_count_sum)) <= word_rebalanced_avg:\n",
    "        print(item, np.round(abs(np.log2(lengths[item][2] / word_count_sum)) / (word_rebalanced_avg / 2), 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d8dadc16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370106\n",
      "370106\n"
     ]
    }
   ],
   "source": [
    "sum = 0\n",
    "for item in lengths:\n",
    "    sum += lengths[item][2]\n",
    "\n",
    "print(sum)\n",
    "print(len(wordlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eedf4a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'': 0, 'a': 9, 'b': 8, 'c': 9, 'd': 9, 'e': 9, 'f': 8, 'g': 8, 'h': 9, 'i': 10, 'j': 7, 'k': 7, 'l': 8, 'm': 9, 'n': 11, 'o': 9, 'p': 10, 'q': 9, 'r': 9, 's': 9, 't': 9, 'u': 10, 'v': 8, 'w': 7, 'x': 9, 'y': 6, 'z': 8}\n"
     ]
    }
   ],
   "source": [
    "avg_letters = {}\n",
    "for item in lengths:\n",
    "    avg_letters.update({item: int(lengths[item][1] / lengths[item][2])})\n",
    "\n",
    "print(avg_letters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
